{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importujemy biblioteki i wczytujemy pliki CSV",
   "id": "edee38625b0d62e9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T15:34:04.753234Z",
     "start_time": "2024-05-21T15:34:01.591494Z"
    }
   },
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from LogParser import  LogParser\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Preprocess data\").getOrCreate()\n",
    "ddos_tf_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"ddos-tcp-syn-flood.csv\")\n",
    "normal_tf_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"normal-traffic.csv\")\n",
    "port_scan_tf_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"port-scanning.csv\")\n",
    "\n",
    "data_frames = {\n",
    "    \"normal-traffic\": normal_tf_df,\n",
    "    \"port-scanning\": port_scan_tf_df,\n",
    "    \"ddos-tcp-syn-flood\": ddos_tf_df,\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 17:34:02 WARN Utils: Your hostname, PC-Debian resolves to a loopback address: 127.0.1.1; using 192.168.0.122 instead (on interface enp4s0)\n",
      "24/05/21 17:34:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/21 17:34:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Wybieramy sobie kolumny zawierające istotne iformacje. Można dodać więcej ale wtedy trzeba pamiętać o noramlizacji w kolejnej komórce.",
   "id": "85d823f49350bef2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:34:04.756568Z",
     "start_time": "2024-05-21T15:34:04.754383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "selected_columns = [\n",
    "    \"frame-time\",\n",
    "    \"ip-src_host\",\n",
    "    \"ip-dst_host\",\n",
    "    \"tcp-connection-syn\",\n",
    "    \"tcp-connection-synack\",\n",
    "    \"tcp-flags_index\",\n",
    "    \"tcp-len\",\n",
    "    \"tcp-seq\",\n",
    "    \"tcp-dstport\",\n",
    "    \"Attack_type\"\n",
    "]"
   ],
   "id": "2a9497dee5eec2b0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Iterujemy po wczytanych ramkach, zamieniamy nazwy kolumn na takie bez kropek i normalizujemy/kodujemy nieliczbowe kolumny (oprócz timestampów, ta kolumna jest modyfikowana później). Odchudzone dane zapisujemy do katalogu `preprocessed_data`",
   "id": "db1f42e07428d995"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:34:12.206585Z",
     "start_time": "2024-05-21T15:34:04.757208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for df_name, df in data_frames.items():\n",
    "\n",
    "    for col_name in df.columns:\n",
    "        new_col_name = re.sub(r'\\.', '-', col_name)\n",
    "        df = df.withColumnRenamed(col_name, new_col_name)\n",
    "        \n",
    "    tcp_flags_indexer = StringIndexer(inputCol=\"tcp-flags\", outputCol=\"tcp-flags_index\")\n",
    "    indexed_df = tcp_flags_indexer.fit(df).transform(df)\n",
    "\n",
    "    indexed_df = indexed_df.select([c for c in df.columns if c in selected_columns])\n",
    "    pandas_df = indexed_df.toPandas()\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    pandas_df[\"ip-src_host\"] = label_encoder.fit_transform(pandas_df[\"ip-src_host\"])\n",
    "    pandas_df[\"ip-dst_host\"] = label_encoder.fit_transform(pandas_df[\"ip-dst_host\"])\n",
    "\n",
    "    pandas_df.to_csv(f'preprocessed_data/{df_name}.csv', index=False)"
   ],
   "id": "de36bc542495320",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Wczytujemy zapisane pliki csv i tworzymy próbki z danymi, gdzie jedna próbka X to lista zawierająca kolejne 32 logi gdzie od każdego timestampa został odjęty timestamp pierwszego loga z listy (w ten sposób timestampy są niewielkimi wartościami liczbowymi a jednocześnie przechowują informację o odległości pomiędzy kolejnymi logami), a próbka Y to pojedynczy numer określający typ ataku/ruchu normalnego dla zagregowanych logów.",
   "id": "9eee815ae2d2be9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:34:19.474875Z",
     "start_time": "2024-05-21T15:34:12.207315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoded_attacks = {\n",
    "    \"normal-traffic\": 0,\n",
    "    \"port-scanning\": 1,\n",
    "    \"ddos-tcp-syn-flood\": 2\n",
    "}\n",
    "x_data = []\n",
    "y_data = []\n",
    "for df_name in data_frames.keys():\n",
    "    df = pd.read_csv(f'preprocessed_data/{df_name}.csv', parse_dates=['frame-time'])\n",
    "    log_series = LogParser.logs_to_series(df, 32)\n",
    "    x_data.extend(log_series)\n",
    "    y_data.extend([encoded_attacks.get(df_name)] * len(log_series))"
   ],
   "id": "51e87dfef0a16366",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/Studies/MSIwC/aiics-project/LogParser.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bucket['frame-time'] = bucket['frame-time'] - bucket['frame-time'].iloc[0]\n",
      "24/05/21 17:34:15 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "/home/kuba/Studies/MSIwC/aiics-project/LogParser.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bucket['frame-time'] = bucket['frame-time'] - bucket['frame-time'].iloc[0]\n",
      "/home/kuba/Studies/MSIwC/aiics-project/LogParser.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bucket['frame-time'] = bucket['frame-time'] - bucket['frame-time'].iloc[0]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:34:19.480383Z",
     "start_time": "2024-05-21T15:34:19.475388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(x_data), len(y_data))\n",
    "print(x_data[0])\n",
    "print(y_data[0])"
   ],
   "id": "8c5b4b40388f52ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32457 32457\n",
      "    frame-time  ip-src_host  ip-dst_host  tcp-connection-syn  \\\n",
      "0        0.000            2            3                 0.0   \n",
      "1        0.000            3            2                 0.0   \n",
      "2        0.000            2            3                 0.0   \n",
      "3        0.000            3            2                 0.0   \n",
      "4        0.319            2            3                 1.0   \n",
      "5        0.319            3            2                 0.0   \n",
      "6        0.322            2            3                 0.0   \n",
      "7        0.322            3            2                 0.0   \n",
      "8        0.323            3            2                 0.0   \n",
      "9        0.329            2            3                 1.0   \n",
      "10       0.329            3            2                 0.0   \n",
      "11       0.330            2            3                 0.0   \n",
      "12       0.330            3            2                 0.0   \n",
      "13       0.330            2            3                 0.0   \n",
      "14       0.330            3            2                 0.0   \n",
      "15       0.332            2            3                 0.0   \n",
      "16       0.332            3            2                 0.0   \n",
      "17       0.333            3            2                 0.0   \n",
      "18       0.336            2            3                 0.0   \n",
      "19       0.336            3            2                 0.0   \n",
      "20       0.336            2            3                 0.0   \n",
      "21       0.336            3            2                 0.0   \n",
      "22       0.336            2            3                 0.0   \n",
      "23       0.337            3            2                 0.0   \n",
      "24       0.337            2            3                 0.0   \n",
      "25       0.345            2            3                 0.0   \n",
      "26       0.345            3            2                 0.0   \n",
      "27       0.345            2            3                 0.0   \n",
      "28       0.351            2            3                 0.0   \n",
      "29       0.351            3            2                 0.0   \n",
      "30       0.352            2            3                 0.0   \n",
      "31       0.352            3            2                 0.0   \n",
      "\n",
      "    tcp-connection-synack  tcp-dstport  tcp-len  tcp-seq  \n",
      "0                     0.0       1883.0      0.0     59.0  \n",
      "1                     0.0      64999.0      0.0      6.0  \n",
      "2                     0.0       1883.0      0.0     59.0  \n",
      "3                     0.0      64999.0      0.0      6.0  \n",
      "4                     0.0       1883.0      0.0      0.0  \n",
      "5                     1.0      61645.0      0.0      0.0  \n",
      "6                     0.0       1883.0     14.0      1.0  \n",
      "7                     0.0      61645.0      0.0      1.0  \n",
      "8                     0.0      61645.0      4.0      1.0  \n",
      "9                     0.0       1883.0      0.0      0.0  \n",
      "10                    1.0      51173.0      0.0      0.0  \n",
      "11                    0.0       1883.0     41.0     15.0  \n",
      "12                    0.0      61645.0      0.0      5.0  \n",
      "13                    0.0       1883.0      2.0     56.0  \n",
      "14                    0.0      61645.0      0.0      5.0  \n",
      "15                    0.0       1883.0     14.0      1.0  \n",
      "16                    0.0      51173.0      0.0      1.0  \n",
      "17                    0.0      51173.0      4.0      1.0  \n",
      "18                    0.0       1883.0     41.0     15.0  \n",
      "19                    0.0      51173.0      0.0      5.0  \n",
      "20                    0.0       1883.0      2.0     56.0  \n",
      "21                    0.0      51173.0      0.0      5.0  \n",
      "22                    0.0       1883.0      0.0      1.0  \n",
      "23                    0.0      61645.0      0.0      6.0  \n",
      "24                    0.0       1883.0      0.0     59.0  \n",
      "25                    0.0       1883.0      0.0      1.0  \n",
      "26                    0.0      51173.0      0.0      6.0  \n",
      "27                    0.0       1883.0      0.0     59.0  \n",
      "28                    0.0       1883.0      0.0     59.0  \n",
      "29                    0.0      61645.0      0.0      6.0  \n",
      "30                    0.0       1883.0      0.0     59.0  \n",
      "31                    0.0      61645.0      0.0      6.0  \n",
      "0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Przed treningem modeli należy jeszcze pomieszać próbki z danymi oraz podzielić na zbiory treningowe i testowe. W sumie dobrze by też było dodać jakiś padding dla przypadków gdzie jednak próbka nie ma 32 logów.",
   "id": "a30f324b609d2a23"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
