{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edee38625b0d62e9",
   "metadata": {},
   "source": [
    "Importujemy biblioteki i wczytujemy pliki CSV"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:03.171286Z",
     "start_time": "2024-06-07T17:25:03.169721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "id": "3f1d232d7ac19ce8",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:03.225304Z",
     "start_time": "2024-06-07T17:25:03.224020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DIRECTORY = 'data'\n",
    "# DIRECTORY = 'generated_data'"
   ],
   "id": "879fa867166b3a6f",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:03.299910Z",
     "start_time": "2024-06-07T17:25:03.233469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "csv_files = [\n",
    "    \"normal-traffic\",\n",
    "    \"port-scanning\",\n",
    "    \"ddos-tcp-syn-flood\"\n",
    "]\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Prepare and sort logs\") \\\n",
    "    .getOrCreate()\n"
   ],
   "id": "5be6f8cbb87d9ce",
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "id": "85d823f49350bef2",
   "metadata": {},
   "source": [
    "Wybieramy sobie kolumny zawierające istotne iformacje. Można dodać więcej ale wtedy trzeba pamiętać o noramlizacji w kolejnej komórce."
   ]
  },
  {
   "cell_type": "code",
   "id": "2a9497dee5eec2b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:03.303180Z",
     "start_time": "2024-06-07T17:25:03.300824Z"
    }
   },
   "source": [
    "selected_columns = [\n",
    "    \"frame-time\",\n",
    "    \"arp-opcode\",\n",
    "    \"arp-hw-size\",\n",
    "    \"ip-src_host\",\n",
    "    \"ip-dst_host\",\n",
    "    \"tcp-ack\",\n",
    "    \"tcp-ack_raw\",\n",
    "    \"tcp-connection-fin\",\n",
    "    \"tcp-connection-rst\",\n",
    "    \"tcp-connection-syn\",\n",
    "    \"tcp-connection-synack\",\n",
    "    \"tcp-dstport\",\n",
    "    \"tcp-flags_index\",\n",
    "    \"tcp-flags-ack\",\n",
    "    \"tcp-len\",\n",
    "    \"tcp-seq\",\n",
    "    \"tcp-srcport\",\n",
    "    \"udp-port\",\n",
    "    \"udp-stream\",\n",
    "    \"udp-time_delta\",\n",
    "    \"dns-qry-name\",\n",
    "    \"dns-qry-name-len_index\",\n",
    "    \"dns-qry-qu_index\",\n",
    "    \"dns-qry-type\",\n",
    "    \"dns-retransmission\",\n",
    "    \"dns-retransmit_request\",\n",
    "    \"dns-retransmit_request_in\",\n",
    "    \"mqtt-conack-flags_index\",\n",
    "    \"mqtt-conflag-cleansess\",\n",
    "    \"mqtt-conflags_index\",\n",
    "    \"mqtt-hdrflags_index\",\n",
    "    \"mqtt-len\",\n",
    "    \"mqtt-msg_index\",\n",
    "    \"mqtt-msgtype\",\n",
    "    \"mqtt-proto_len\",\n",
    "    \"mqtt-protoname_index\",\n",
    "    \"mqtt-topic_index\",\n",
    "    \"mqtt-topic_len\",\n",
    "    \"mqtt-ver\",\n",
    "    \"Attack_type\"\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "id": "db1f42e07428d995",
   "metadata": {},
   "source": [
    "Iterujemy po wczytanych ramkach, zamieniamy nazwy kolumn na takie bez kropek i normalizujemy/kodujemy nieliczbowe kolumny (oprócz timestampów, ta kolumna jest modyfikowana później). Odchudzone dane zapisujemy do katalogu `preprocessed_data`"
   ]
  },
  {
   "cell_type": "code",
   "id": "cd6456f55a4e90e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:03.317966Z",
     "start_time": "2024-06-07T17:25:03.303748Z"
    }
   },
   "source": [
    "def timestamp_to_epoch(timestamp):\n",
    "    dt = datetime.fromisoformat(f'2024-06-05 {str(timestamp).strip().split()[1]}')\n",
    "    return dt.timestamp()\n"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "id": "de36bc542495320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:31.197085Z",
     "start_time": "2024-06-07T17:25:03.318725Z"
    }
   },
   "source": [
    "for file in csv_files:\n",
    "    \n",
    "    df = spark.read.csv(DIRECTORY + '/' + file + '.csv', header=True, inferSchema=True)\n",
    "\n",
    "    for col_name in df.columns:\n",
    "        new_col_name = re.sub(r'\\.', '-', col_name)\n",
    "        df = df.withColumnRenamed(col_name, new_col_name)\n",
    "    \n",
    "    tcp_flags_indexer = StringIndexer(inputCol=\"tcp-flags\", outputCol=\"tcp-flags_index\")\n",
    "    indexed_df = tcp_flags_indexer.fit(df).transform(df)\n",
    "\n",
    "    dns_qry_name_len_indexer = StringIndexer(inputCol=\"dns-qry-name-len\", outputCol=\"dns-qry-name-len_index\")\n",
    "    indexed_df = dns_qry_name_len_indexer.fit(indexed_df).transform(indexed_df)\n",
    "    dns_qry_qu_indexer = StringIndexer(inputCol=\"dns-qry-qu\", outputCol=\"dns-qry-qu_index\")\n",
    "    indexed_df = dns_qry_qu_indexer.fit(indexed_df).transform(indexed_df)\n",
    "\n",
    "    mqtt_conack_flags_indexer = StringIndexer(inputCol=\"mqtt-conack-flags\", outputCol=\"mqtt-conack-flags_index\")\n",
    "    indexed_df = mqtt_conack_flags_indexer.fit(indexed_df).transform(indexed_df)\n",
    "    mqtt_conflags = StringIndexer(inputCol=\"mqtt-conflags\", outputCol=\"mqtt-conflags_index\")\n",
    "    indexed_df = mqtt_conflags.fit(indexed_df).transform(indexed_df)\n",
    "\n",
    "    mqtt_hdrflags = StringIndexer(inputCol=\"mqtt-hdrflags\", outputCol=\"mqtt-hdrflags_index\")\n",
    "    indexed_df = mqtt_hdrflags.fit(indexed_df).transform(indexed_df)\n",
    "    mqtt_msg = StringIndexer(inputCol=\"mqtt-msg\", outputCol=\"mqtt-msg_index\")\n",
    "    indexed_df = mqtt_msg.fit(indexed_df).transform(indexed_df)\n",
    "\n",
    "    mqtt_protoname = StringIndexer(inputCol=\"mqtt-protoname\", outputCol=\"mqtt-protoname_index\")\n",
    "    indexed_df = mqtt_protoname.fit(indexed_df).transform(indexed_df)\n",
    "\n",
    "    mqtt_topic = StringIndexer(inputCol=\"mqtt-topic\", outputCol=\"mqtt-topic_index\")\n",
    "    indexed_df = mqtt_topic.fit(indexed_df).transform(indexed_df)\n",
    "\n",
    "    pandas_df = indexed_df.select(selected_columns).toPandas()\n",
    "\n",
    "    all_ips = pd.concat([pandas_df[\"ip-src_host\"], pandas_df[\"ip-dst_host\"]]).unique()\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(all_ips)\n",
    "    pandas_df[\"ip-src_host\"] = label_encoder.transform(pandas_df[\"ip-src_host\"])\n",
    "    pandas_df[\"ip-dst_host\"] = label_encoder.transform(pandas_df[\"ip-dst_host\"])\n",
    "    pandas_df['frame-time'] = pandas_df['frame-time'].apply(timestamp_to_epoch)\n",
    "\n",
    "    pandas_df = pandas_df.reindex(sorted(pandas_df.columns), axis=1)\n",
    "    pandas_df.to_csv(f'{DIRECTORY}/{file}-preprocessed.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:31.613753Z",
     "start_time": "2024-06-07T17:25:31.197790Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "id": "53f35ad91bae1ace",
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "id": "9eee815ae2d2be9a",
   "metadata": {},
   "source": [
    "Wczytujemy zapisane pliki csv i tworzymy próbki z danymi, gdzie jedna próbka X to lista zawierająca kolejne 32 logi gdzie od każdego timestampa został odjęty timestamp pierwszego loga z listy (w ten sposób timestampy są niewielkimi wartościami liczbowymi a jednocześnie przechowują informację o odległości pomiędzy kolejnymi logami), a próbka Y to pojedynczy numer określający typ ataku/ruchu normalnego dla zagregowanych logów."
   ]
  },
  {
   "cell_type": "code",
   "id": "8818a5ed1dd15f48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:31.618031Z",
     "start_time": "2024-06-07T17:25:31.616009Z"
    }
   },
   "source": [
    "def logs_to_series(df, logs_per_bucket):\n",
    "    del df['Attack_type']\n",
    "    buckets = []\n",
    "\n",
    "    for i in range(0, df.shape[0], logs_per_bucket):\n",
    "        if df.shape[0] >= i + logs_per_bucket:\n",
    "            bucket = df.iloc[i:i + logs_per_bucket]\n",
    "            bucket['frame-time'] = bucket['frame-time'] - bucket['frame-time'].iloc[0]\n",
    "            buckets.append(bucket)\n",
    "\n",
    "    return buckets"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "51e87dfef0a16366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:38.941445Z",
     "start_time": "2024-06-07T17:25:31.618648Z"
    }
   },
   "source": [
    "encoded_attacks = {\n",
    "    \"normal-traffic\": 0,\n",
    "    \"port-scanning\": 1,\n",
    "    \"ddos-tcp-syn-flood\": 2\n",
    "}\n",
    "x_data = []\n",
    "y_data = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(f'{DIRECTORY}/{file}-preprocessed.csv')\n",
    "    log_series = logs_to_series(df, 32)\n",
    "    x_data.extend(log_series)\n",
    "    y_data.extend([encoded_attacks.get(file)] * len(log_series))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57287/1193988674.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bucket['frame-time'] = bucket['frame-time'] - bucket['frame-time'].iloc[0]\n",
      "/tmp/ipykernel_57287/1193988674.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bucket['frame-time'] = bucket['frame-time'] - bucket['frame-time'].iloc[0]\n",
      "/tmp/ipykernel_57287/1193988674.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bucket['frame-time'] = bucket['frame-time'] - bucket['frame-time'].iloc[0]\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "id": "a30f324b609d2a23",
   "metadata": {},
   "source": [
    "Przed treningem modeli należy jeszcze pomieszać próbki z danymi oraz podzielić na zbiory treningowe i testowe. W sumie dobrze by też było dodać jakiś padding dla przypadków gdzie jednak próbka nie ma 32 logów."
   ]
  },
  {
   "cell_type": "code",
   "id": "c5e4b191add743bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:39.871484Z",
     "start_time": "2024-06-07T17:25:38.942034Z"
    }
   },
   "source": [
    "output_path = f'{DIRECTORY}/processed_data.pkl'\n",
    "print(\"Writing log series into \", output_path)\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump((x_data, y_data), f)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing log series into  data/processed_data.pkl\n"
     ]
    }
   ],
   "execution_count": 67
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
