{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f1d232d7ac19ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:03.171286Z",
     "start_time": "2024-06-07T17:25:03.169721Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879fa867166b3a6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:03.225304Z",
     "start_time": "2024-06-07T17:25:03.224020Z"
    }
   },
   "outputs": [],
   "source": [
    "DIRECTORY = '..'\n",
    "# DIRECTORY = 'generated_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5be6f8cbb87d9ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:03.299910Z",
     "start_time": "2024-06-07T17:25:03.233469Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/14 18:09:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "csv_files = [\n",
    "    \"normal-traffic\",\n",
    "    \"port-scanning\",\n",
    "    \"ddos-tcp-syn-flood\"\n",
    "]\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Prepare and sort logs\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d823f49350bef2",
   "metadata": {},
   "source": [
    "Wybieramy sobie kolumny zawierające istotne iformacje. Można dodać więcej ale wtedy trzeba pamiętać o noramlizacji w kolejnej komórce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a9497dee5eec2b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:03.303180Z",
     "start_time": "2024-06-07T17:25:03.300824Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_columns = [\n",
    "    \"frame-time\",\n",
    "    \"arp-opcode\",\n",
    "    \"arp-hw-size\",\n",
    "    \"ip-src_host\",\n",
    "    \"ip-dst_host\",\n",
    "    \"tcp-ack\",\n",
    "    \"tcp-ack_raw\",\n",
    "    \"tcp-connection-fin\",\n",
    "    \"tcp-connection-rst\",\n",
    "    \"tcp-connection-syn\",\n",
    "    \"tcp-connection-synack\",\n",
    "    \"tcp-dstport\",\n",
    "    \"tcp-flags_index\",\n",
    "    \"tcp-flags-ack\",\n",
    "    \"tcp-len\",\n",
    "    \"tcp-seq\",\n",
    "    \"tcp-srcport\",\n",
    "    \"udp-port\",\n",
    "    \"udp-stream\",\n",
    "    \"udp-time_delta\",\n",
    "    \"dns-qry-name\",\n",
    "    \"dns-qry-name-len_index\",\n",
    "    \"dns-qry-qu_index\",\n",
    "    \"dns-qry-type\",\n",
    "    \"dns-retransmission\",\n",
    "    \"dns-retransmit_request\",\n",
    "    \"dns-retransmit_request_in\",\n",
    "    \"mqtt-conack-flags_index\",\n",
    "    \"mqtt-conflag-cleansess\",\n",
    "    \"mqtt-conflags_index\",\n",
    "    \"mqtt-hdrflags_index\",\n",
    "    \"mqtt-len\",\n",
    "    \"mqtt-msg_index\",\n",
    "    \"mqtt-msgtype\",\n",
    "    \"mqtt-proto_len\",\n",
    "    \"mqtt-protoname_index\",\n",
    "    \"mqtt-topic_index\",\n",
    "    \"mqtt-topic_len\",\n",
    "    \"mqtt-ver\",\n",
    "    \"Attack_type\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f42e07428d995",
   "metadata": {},
   "source": [
    "Iterujemy po wczytanych ramkach, zamieniamy nazwy kolumn na takie bez kropek i normalizujemy/kodujemy nieliczbowe kolumny (oprócz timestampów, ta kolumna jest modyfikowana później). Odchudzone dane zapisujemy do katalogu `preprocessed_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd6456f55a4e90e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:03.317966Z",
     "start_time": "2024-06-07T17:25:03.303748Z"
    }
   },
   "outputs": [],
   "source": [
    "def timestamp_to_epoch(timestamp):\n",
    "    dt = datetime.fromisoformat(f'2024-06-05 {str(timestamp).strip().split()[1]}')\n",
    "    return dt.timestamp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b46c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_data(pandas_df):\n",
    "    columns_to_normalize = ['tcp-ack_raw', 'tcp-ack', 'tcp-dstport', 'tcp-len', 'tcp-seq', 'tcp-srcport']\n",
    "    scaler = MinMaxScaler()\n",
    "    pandas_df[columns_to_normalize] = scaler.fit_transform(pandas_df[columns_to_normalize])\n",
    "    return pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de36bc542495320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:31.197085Z",
     "start_time": "2024-06-07T17:25:03.318725Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/14 18:12:00 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for file in csv_files:\n",
    "    \n",
    "    df = spark.read.csv(DIRECTORY + '/' + file + '.csv', header=True, inferSchema=True)\n",
    "\n",
    "    for col_name in df.columns:\n",
    "        new_col_name = re.sub(r'\\.', '-', col_name)\n",
    "        df = df.withColumnRenamed(col_name, new_col_name)\n",
    "    \n",
    "    tcp_flags_indexer = StringIndexer(inputCol=\"tcp-flags\", outputCol=\"tcp-flags_index\")\n",
    "    indexed_df = tcp_flags_indexer.fit(df).transform(df)\n",
    "\n",
    "    dns_qry_name_len_indexer = StringIndexer(inputCol=\"dns-qry-name-len\", outputCol=\"dns-qry-name-len_index\")\n",
    "    indexed_df = dns_qry_name_len_indexer.fit(indexed_df).transform(indexed_df)\n",
    "    dns_qry_qu_indexer = StringIndexer(inputCol=\"dns-qry-qu\", outputCol=\"dns-qry-qu_index\")\n",
    "    indexed_df = dns_qry_qu_indexer.fit(indexed_df).transform(indexed_df)\n",
    "\n",
    "    mqtt_conack_flags_indexer = StringIndexer(inputCol=\"mqtt-conack-flags\", outputCol=\"mqtt-conack-flags_index\")\n",
    "    indexed_df = mqtt_conack_flags_indexer.fit(indexed_df).transform(indexed_df)\n",
    "    mqtt_conflags = StringIndexer(inputCol=\"mqtt-conflags\", outputCol=\"mqtt-conflags_index\")\n",
    "    indexed_df = mqtt_conflags.fit(indexed_df).transform(indexed_df)\n",
    "\n",
    "    mqtt_hdrflags = StringIndexer(inputCol=\"mqtt-hdrflags\", outputCol=\"mqtt-hdrflags_index\")\n",
    "    indexed_df = mqtt_hdrflags.fit(indexed_df).transform(indexed_df)\n",
    "    mqtt_msg = StringIndexer(inputCol=\"mqtt-msg\", outputCol=\"mqtt-msg_index\")\n",
    "    indexed_df = mqtt_msg.fit(indexed_df).transform(indexed_df)\n",
    "\n",
    "    mqtt_protoname = StringIndexer(inputCol=\"mqtt-protoname\", outputCol=\"mqtt-protoname_index\")\n",
    "    indexed_df = mqtt_protoname.fit(indexed_df).transform(indexed_df)\n",
    "\n",
    "    mqtt_topic = StringIndexer(inputCol=\"mqtt-topic\", outputCol=\"mqtt-topic_index\")\n",
    "    indexed_df = mqtt_topic.fit(indexed_df).transform(indexed_df)\n",
    "\n",
    "    pandas_df = indexed_df.select(selected_columns).toPandas()\n",
    "    pandas_df = pandas_df.drop_duplicates()\n",
    "    pandas_df = normalize_data(pandas_df)\n",
    "\n",
    "    all_ips = pd.concat([pandas_df[\"ip-src_host\"], pandas_df[\"ip-dst_host\"]]).unique()\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(all_ips)\n",
    "    pandas_df[\"ip-src_host\"] = label_encoder.transform(pandas_df[\"ip-src_host\"])\n",
    "    pandas_df[\"ip-dst_host\"] = label_encoder.transform(pandas_df[\"ip-dst_host\"])\n",
    "    pandas_df['frame-time'] = pandas_df['frame-time'].apply(timestamp_to_epoch)\n",
    "\n",
    "    pandas_df = pandas_df.reindex(sorted(pandas_df.columns), axis=1)\n",
    "    pandas_df.to_csv(f'{DIRECTORY}/{file}-preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53f35ad91bae1ace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:31.613753Z",
     "start_time": "2024-06-07T17:25:31.197790Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee815ae2d2be9a",
   "metadata": {},
   "source": [
    "Wczytujemy zapisane pliki csv i tworzymy próbki z danymi, gdzie jedna próbka X to lista zawierająca kolejne 32 logi gdzie od każdego timestampa został odjęty timestamp pierwszego loga z listy (w ten sposób timestampy są niewielkimi wartościami liczbowymi a jednocześnie przechowują informację o odległości pomiędzy kolejnymi logami), a próbka Y to pojedynczy numer określający typ ataku/ruchu normalnego dla zagregowanych logów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8818a5ed1dd15f48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:31.618031Z",
     "start_time": "2024-06-07T17:25:31.616009Z"
    }
   },
   "outputs": [],
   "source": [
    "def logs_to_series(df, logs_per_bucket):\n",
    "    del df['Attack_type']\n",
    "    buckets = []\n",
    "\n",
    "    for i in range(0, df.shape[0], logs_per_bucket):\n",
    "        if df.shape[0] >= i + logs_per_bucket:\n",
    "            bucket = df.iloc[i:i + logs_per_bucket]\n",
    "            bucket['frame-time'] = bucket['frame-time'] - bucket['frame-time'].iloc[0]\n",
    "            buckets.append(bucket)\n",
    "\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51e87dfef0a16366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:38.941445Z",
     "start_time": "2024-06-07T17:25:31.618648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11120/2040401593.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bucket['frame-time'] = bucket['frame-time'] - bucket['frame-time'].iloc[0]\n",
      "/tmp/ipykernel_11120/2040401593.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bucket['frame-time'] = bucket['frame-time'] - bucket['frame-time'].iloc[0]\n",
      "/tmp/ipykernel_11120/2040401593.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bucket['frame-time'] = bucket['frame-time'] - bucket['frame-time'].iloc[0]\n"
     ]
    }
   ],
   "source": [
    "encoded_attacks = {\n",
    "    \"normal-traffic\": 0,\n",
    "    \"port-scanning\": 1,\n",
    "    \"ddos-tcp-syn-flood\": 2\n",
    "}\n",
    "x_data = []\n",
    "y_data = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(f'{DIRECTORY}/{file}-preprocessed.csv')\n",
    "    log_series = logs_to_series(df, 32)\n",
    "    x_data.extend(log_series)\n",
    "    y_data.extend([encoded_attacks.get(file)] * len(log_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f324b609d2a23",
   "metadata": {},
   "source": [
    "Przed treningem modeli należy jeszcze pomieszać próbki z danymi oraz podzielić na zbiory treningowe i testowe. W sumie dobrze by też było dodać jakiś padding dla przypadków gdzie jednak próbka nie ma 32 logów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5e4b191add743bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T17:25:39.871484Z",
     "start_time": "2024-06-07T17:25:38.942034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing log series into  ../processed_data.pkl\n"
     ]
    }
   ],
   "source": [
    "output_path = f'{DIRECTORY}/processed_data.pkl'\n",
    "print(\"Writing log series into \", output_path)\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump((x_data, y_data), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "455e3b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to file: ./generated_data/normal-traffic.csv\n",
      "Saving data to file: ./generated_data/port-scanning.csv\n",
      "Saving data to file: ./generated_data/ddos-tcp-syn-flood.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "TRAFFIC_TYPES = {\n",
    "    \"normal-traffic\": \"Normal\",\n",
    "    \"port-scanning\": \"Port_Scanning\",\n",
    "    \"ddos-tcp-syn-flood\": \"DDoS_TCP\"\n",
    "}\n",
    "\n",
    "\n",
    "def generate_logs_for_traffic(traffic_type, logs_count):\n",
    "    match traffic_type:\n",
    "        case 'Normal':\n",
    "            return generate_logs_for_normal_traffic(logs_count)\n",
    "        case 'Port_Scanning':\n",
    "            return generate_logs_for_port_scanning(logs_count)\n",
    "        case 'DDoS_TCP':\n",
    "            return generate_logs_for_ddos_tcp(logs_count)\n",
    "\n",
    "\n",
    "def generate_logs_for_normal_traffic(logs_count):\n",
    "    logs = []\n",
    "    previous_timestamp = datetime.now().astimezone()\n",
    "    while len(logs) <= logs_count:\n",
    "        logs.append(generate_normal_traffic_log(previous_timestamp))\n",
    "        previous_timestamp = datetime.strptime(logs[-1][0], '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "    return logs\n",
    "\n",
    "\n",
    "def generate_normal_traffic_log(previous_timestamp):\n",
    "    frame_time = (previous_timestamp + timedelta(milliseconds=random.randint(5, 20))).strftime('%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "    arp_opcode = 0.0\n",
    "    arp_hw_siz = 0.0\n",
    "    ip_src_host = draw_ip_address()\n",
    "    ip_dst_host = draw_ip_address()\n",
    "    tcp_ack = np.random.choice([0.0, 1.0, 5.0, 6.0, 15.0, 56.0, 59.0], p=[0.13, 0.24, 0.13, 0.19, 0.06, 0.06, 0.19])\n",
    "    tcp_ack_raw = 0.0 if np.random.choice([0.0, 1.0], p=[0.2, 0.8]) == 0.0 else random.randint(9749767.0, 4292762365.0)\n",
    "    tcp_connection_fin = np.random.choice([0.0, 1.0], p=[0.88, 0.12])\n",
    "    tcp_connection_rst = np.random.choice([0.0, 1.0], p=[0.88, 0.12])\n",
    "    tcp_connection_syn = np.random.choice([0.0, 1.0], p=[0.92, 0.08])\n",
    "    tcp_connection_synack = np.random.choice([0.0, 1.0], p=[0.93, 0.07])\n",
    "    tcp_dstport = random.randint(51173, 65156)\n",
    "    tcp_srcport = random.randint(51173, 65156)\n",
    "    tcp_len = np.random.choice([0.0, 2.0, 4.0, 14.0, 41.0], p=[0.76, 0.06, 0.06, 0.06, 0.06])\n",
    "    tcp_seq = np.random.choice([0.0, 1.0, 5.0, 6.0, 15.0, 56.0, 59.0], p=[0.13, 0.24, 0.13, 0.19, 0.06, 0.06, 0.19])\n",
    "    tcp_flags = np.random.choice(\n",
    "        ['0.0', '0x00000002', '0x00000004', '0x00000010', '0x00000011', '0x00000012', '0x00000018', '0x00000019'], \n",
    "        p=[0.01, 0.06, 0.12, 0.44, 0.06, 0.07, 0.18, 0.06]\n",
    "    )\n",
    "    tcp_flags_ack = np.random.choice([0.0, 1.0], p=[0.24, 0.76])\n",
    "    udp_port = 0.0\n",
    "    udp_stream = 0.0\n",
    "    udp_time_delta = 0.0\n",
    "    dns_qry_name = 0.0\n",
    "    dns_qry_name_len = 0\n",
    "    dns_qry_qu = 0\n",
    "    dns_qry_type = 0.0\n",
    "    dns_retransmission = 0.0\n",
    "    dns_retransmit_request = 0.0\n",
    "    dns_retransmit_request_in = 0.0\n",
    "    mqtt_conack_flags = np.random.choice(['0', '0x00000000'], p=[0.93, 0.07])\n",
    "    mqtt_conflag_cleansess = np.random.choice([0.0, 1.0], p=[0.94, 0.06])\n",
    "    mqtt_conflags = np.random.choice(['0', '0x00000002'], p=[0.93, 0.07])\n",
    "    mqtt_hdrflags = np.random.choice(\n",
    "        ['0.0', '0x00000010', '0x00000020', '0x00000030', '0x000000e0'], \n",
    "        p=[0.76, 0.06, 0.06, 0.06, 0.06]\n",
    "    )\n",
    "    mqtt_len = np.random.choice([0, 0.0, 2.0, 12.0, 39.0], p=[0.76, 0.06, 0.06, 0.06, 0.06])\n",
    "    mqtt_msg = 0\n",
    "    mqtt_msgtype = np.random.choice([0.0, 1.0, 2.0, 3.0, 14.0], p=[0.76, 0.06, 0.06, 0.06, 0.06])\n",
    "    mqtt_proto_len = np.random.choice([0, 4.0], p=[0.94, 0.06])\n",
    "    mqtt_protoname = np.random.choice(['0', 'MQTT'], p=[0.94, 0.06])\n",
    "    mqtt_topic = 0\n",
    "    mqtt_topic_len = 0.0\n",
    "    mqtt_ver = np.random.choice([0, 4.0], p=[0.94, 0.06])\n",
    "\n",
    "    return [frame_time, arp_opcode, arp_hw_siz, ip_src_host, ip_dst_host, tcp_ack, tcp_ack_raw,\n",
    "            tcp_connection_fin, tcp_connection_rst, tcp_connection_syn, tcp_connection_synack,\n",
    "            tcp_srcport, tcp_dstport, tcp_flags, tcp_flags_ack, tcp_len, tcp_seq, udp_port,\n",
    "            udp_stream, udp_time_delta, dns_qry_name, dns_qry_name_len, dns_qry_qu, dns_qry_type, \n",
    "            dns_retransmission, dns_retransmit_request, dns_retransmit_request_in, mqtt_conack_flags, \n",
    "            mqtt_conflag_cleansess, mqtt_conflags, mqtt_hdrflags, mqtt_len, mqtt_msg, mqtt_msgtype, \n",
    "            mqtt_proto_len, mqtt_protoname, mqtt_topic, mqtt_topic_len, mqtt_ver, 'Normal']\n",
    "\n",
    "\n",
    "def generate_logs_for_port_scanning(logs_count):\n",
    "    logs = []\n",
    "    hacker_ip = draw_ip_address()\n",
    "    victim_ip = draw_ip_address()\n",
    "    victim_port = 1000\n",
    "    previous_timestamp = datetime.now().astimezone()\n",
    "    while len(logs) <= logs_count:\n",
    "        logs.extend(generate_port_scanning_log_pair(previous_timestamp, hacker_ip, victim_ip, victim_port))\n",
    "        previous_timestamp = datetime.strptime(logs[-1][0], '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "        victim_port += 1\n",
    "    return logs\n",
    "\n",
    "\n",
    "def generate_port_scanning_log_pair(previous_timestamp, hacker_ip, victim_ip, victim_port):\n",
    "    frame_time = (previous_timestamp + timedelta(milliseconds=random.randint(1, 5))).strftime('%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "    hacker_port = 80\n",
    "    arp_opcode = 0.0\n",
    "    arp_hw_siz = 0.0\n",
    "    tcp_ack = random.randint(341294.0, 2147250934.0)\n",
    "    tcp_connection_fin = 0.0\n",
    "    tcp_connection_synack = 0.0\n",
    "    tcp_len = 0.0\n",
    "    udp_port = 0.0\n",
    "    udp_stream = 0.0\n",
    "    udp_time_delta = 0.0\n",
    "    dns_qry_name = 0.0\n",
    "    dns_qry_name_len = 0.0\n",
    "    dns_qry_qu = 0.0\n",
    "    dns_qry_type = 0.0\n",
    "    dns_retransmission = 0.0\n",
    "    dns_retransmit_request = 0.0\n",
    "    dns_retransmit_request_in = 0.0\n",
    "    mqtt_conack_flags = 0.0\n",
    "    mqtt_conflag_cleansess = 0.0\n",
    "    mqtt_conflags = 0.0\n",
    "    mqtt_hdrflags = 0.0\n",
    "    mqtt_len = 0.0\n",
    "    mqtt_msg = 0.0\n",
    "    mqtt_msgtype = 0.0\n",
    "    mqtt_proto_len = 0.0\n",
    "    mqtt_protoname = 0.0\n",
    "    mqtt_topic = 0.0\n",
    "    mqtt_topic_len = 0.0\n",
    "    mqtt_ver = 0.0\n",
    "    traffic_type = 'Port_Scanning'\n",
    "\n",
    "    return [\n",
    "            [\n",
    "                frame_time, arp_opcode, arp_hw_siz, hacker_ip, victim_ip, tcp_ack, tcp_ack, tcp_connection_fin,\n",
    "                0.0, 1.0, tcp_connection_synack, hacker_port, victim_port, '0x00000014', 1.0, tcp_len, 1.0,\n",
    "                udp_port, udp_stream, udp_time_delta, dns_qry_name, dns_qry_name_len, dns_qry_qu, dns_qry_type, \n",
    "                dns_retransmission, dns_retransmit_request, dns_retransmit_request_in, mqtt_conack_flags, \n",
    "                mqtt_conflag_cleansess, mqtt_conflags, mqtt_hdrflags, mqtt_len, mqtt_msg, mqtt_msgtype, \n",
    "                mqtt_proto_len, mqtt_protoname, mqtt_topic, mqtt_topic_len, mqtt_ver, traffic_type\n",
    "            ],\n",
    "            [\n",
    "                frame_time, arp_opcode, arp_hw_siz, victim_ip, hacker_ip, 1.0, tcp_ack, tcp_connection_fin,\n",
    "                1.0, 0.0, tcp_connection_synack, victim_port, hacker_port, '0x00000002', 0.0, tcp_len, 0.0,\n",
    "                udp_port, udp_stream, udp_time_delta, dns_qry_name, dns_qry_name_len, dns_qry_qu, dns_qry_type, \n",
    "                dns_retransmission, dns_retransmit_request, dns_retransmit_request_in, mqtt_conack_flags, \n",
    "                mqtt_conflag_cleansess, mqtt_conflags, mqtt_hdrflags, mqtt_len, mqtt_msg, mqtt_msgtype, \n",
    "                mqtt_proto_len, mqtt_protoname, mqtt_topic, mqtt_topic_len, mqtt_ver,traffic_type\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "\n",
    "def generate_logs_for_ddos_tcp(logs_count):\n",
    "    logs = []\n",
    "    victim_ip = draw_ip_address()\n",
    "    hacker_port = 30000\n",
    "    previous_timestamp = datetime.now().astimezone()\n",
    "    while len(logs) < logs_count:\n",
    "        logs.extend(generate_ddos_log_pair(previous_timestamp, victim_ip, hacker_port))\n",
    "        previous_timestamp = datetime.strptime(logs[-1][0], '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "        hacker_port += 1\n",
    "    return logs\n",
    "\n",
    "\n",
    "def generate_ddos_log_pair(previous_timestamp, victim_ip, hacker_port):\n",
    "    if random.randint(1, 10) == 1:\n",
    "        frame_time = (previous_timestamp + timedelta(milliseconds=1)).strftime('%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "    else:\n",
    "        frame_time = previous_timestamp.strftime('%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "    hacker_ip = draw_ip_address()\n",
    "    victim_port = 80\n",
    "    arp_opcode = 0.0\n",
    "    arp_hw_siz = 0.0\n",
    "    tcp_ack = random.randint(341294.0, 2147250934.0)\n",
    "    tcp_connection_fin = 0.0\n",
    "    tcp_connection_synack = 0.0\n",
    "    udp_port = 0.0\n",
    "    udp_stream = 0.0\n",
    "    udp_time_delta = 0.0\n",
    "    dns_qry_name = 0.0\n",
    "    dns_qry_name_len = 0.0\n",
    "    dns_qry_qu = 0.0\n",
    "    dns_qry_type = 0.0\n",
    "    dns_retransmission = 0.0\n",
    "    dns_retransmit_request = 0.0\n",
    "    dns_retransmit_request_in = 0.0\n",
    "    mqtt_conack_flags = 0.0\n",
    "    mqtt_conflag_cleansess = 0.0\n",
    "    mqtt_conflags = 0.0\n",
    "    mqtt_hdrflags = 0.0\n",
    "    mqtt_len = 0.0\n",
    "    mqtt_msg = 0.0\n",
    "    mqtt_msgtype = 0.0\n",
    "    mqtt_proto_len = 0.0\n",
    "    mqtt_protoname = 0.0\n",
    "    mqtt_topic = 0.0\n",
    "    mqtt_topic_len = 0.0\n",
    "    mqtt_ver = 0.0\n",
    "    traffic_type = 'DDoS_TCP'\n",
    "\n",
    "    log_pair = [\n",
    "        [\n",
    "            frame_time, arp_opcode, arp_hw_siz, hacker_ip, victim_ip, tcp_ack, tcp_ack, tcp_connection_fin,\n",
    "            0.0, 1.0, tcp_connection_synack, hacker_port, victim_port, '0x00000002', 0.0, 120.0, 0.0,\n",
    "            udp_port, udp_stream, udp_time_delta, dns_qry_name, dns_qry_name_len, dns_qry_qu, dns_qry_type,\n",
    "            dns_retransmission, dns_retransmit_request, dns_retransmit_request_in, mqtt_conack_flags,\n",
    "            mqtt_conflag_cleansess, mqtt_conflags, mqtt_hdrflags, mqtt_len, mqtt_msg, mqtt_msgtype,\n",
    "            mqtt_proto_len, mqtt_protoname, mqtt_topic, mqtt_topic_len, mqtt_ver, traffic_type\n",
    "        ],\n",
    "        [\n",
    "            frame_time, arp_opcode, arp_hw_siz, victim_ip, hacker_ip, 121.0, tcp_ack, tcp_connection_fin,\n",
    "            1.0, 0.0, tcp_connection_synack, victim_port, hacker_port, '0x00000014', 1.0, 0.0, 1.0,\n",
    "            udp_port, udp_stream, udp_time_delta, dns_qry_name, dns_qry_name_len, dns_qry_qu, dns_qry_type,\n",
    "            dns_retransmission, dns_retransmit_request, dns_retransmit_request_in, mqtt_conack_flags,\n",
    "            mqtt_conflag_cleansess, mqtt_conflags, mqtt_hdrflags, mqtt_len, mqtt_msg, mqtt_msgtype,\n",
    "            mqtt_proto_len, mqtt_protoname, mqtt_topic, mqtt_topic_len, mqtt_ver, traffic_type\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    if random.randint(1, 10) == 1:\n",
    "        log_pair.pop()\n",
    "\n",
    "    return log_pair\n",
    "\n",
    "\n",
    "def draw_ip_address():\n",
    "    return str(random.randint(0, 255)) + '.' \\\n",
    "        + str(random.randint(0, 255)) + '.' \\\n",
    "        + str(random.randint(0, 255)) + '.' \\\n",
    "        + str(random.randint(0, 255))\n",
    "\n",
    "\n",
    "OUTDIR = './generated_data'\n",
    "if not os.path.exists(OUTDIR):\n",
    "    os.mkdir(OUTDIR)\n",
    "\n",
    "columns = [\n",
    "    \"frame-time\",\n",
    "    \"arp-opcode\",\n",
    "    \"arp-hw-size\",\n",
    "    \"ip-src_host\",\n",
    "    \"ip-dst_host\",\n",
    "    \"tcp-ack\",\n",
    "    \"tcp-ack_raw\",\n",
    "    \"tcp-connection-fin\",\n",
    "    \"tcp-connection-rst\",\n",
    "    \"tcp-connection-syn\",\n",
    "    \"tcp-connection-synack\",\n",
    "    \"tcp-srcport\",\n",
    "    \"tcp-dstport\",\n",
    "    \"tcp-flags\",\n",
    "    \"tcp-flags-ack\",\n",
    "    \"tcp-len\",\n",
    "    \"tcp-seq\",\n",
    "    \"udp-port\",\n",
    "    \"udp-stream\",\n",
    "    \"udp-time_delta\",\n",
    "    \"dns-qry-name\",\n",
    "    \"dns-qry-name-len\",\n",
    "    \"dns-qry-qu\",\n",
    "    \"dns-qry-type\",\n",
    "    \"dns-retransmission\",\n",
    "    \"dns-retransmit_request\",\n",
    "    \"dns-retransmit_request_in\",\n",
    "    \"mqtt-conack-flags\",\n",
    "    \"mqtt-conflag-cleansess\",\n",
    "    \"mqtt-conflags\",\n",
    "    \"mqtt-hdrflags\",\n",
    "    \"mqtt-len\",\n",
    "    \"mqtt-msg\",\n",
    "    \"mqtt-msgtype\",\n",
    "    \"mqtt-proto_len\",\n",
    "    \"mqtt-protoname\",\n",
    "    \"mqtt-topic\",\n",
    "    \"mqtt-topic_len\",\n",
    "    \"mqtt-ver\",\n",
    "    \"Attack_type\"\n",
    "]\n",
    "    \n",
    "for filename, traffic_type in TRAFFIC_TYPES.items():\n",
    "    generated_logs = generate_logs_for_traffic(traffic_type, 10000)\n",
    "    \n",
    "    data = pd.DataFrame(generated_logs, columns=columns)\n",
    "    print(f'Saving data to file: {OUTDIR}/{filename}.csv')\n",
    "    data.to_csv(f'{OUTDIR}/{filename}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7c77916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd67b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        x, y = pickle.load(f)\n",
    "\n",
    "    rows_count = x[0].shape[0]\n",
    "    x = [bucket for bucket in x if bucket.shape[0] == rows_count]\n",
    "\n",
    "    x = np.array([bucket.to_numpy().flatten() for bucket in x])\n",
    "    y = np.array(y[:len(x)])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4dcf598",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_np, y_data_np = load_data('../processed_data.pkl')\n",
    "x_gen, y_gen = load_data('./generated_data/processed_data.pkl')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data_np, y_data_np, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5580fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "def evaluate_model(clf, x_gen, y_gen):\n",
    "    y_pred = clf.predict(x_gen)\n",
    "    y_proba = clf.predict_proba(x_gen)\n",
    "\n",
    "    print(f'Accuracy: {accuracy_score(y_gen, y_pred)}')\n",
    "    print(f'Confusion Matrix:\\n{confusion_matrix(y_gen, y_pred)}')\n",
    "    print(f'Classification Report:\\n{classification_report(y_gen, y_pred,)}')\n",
    "    \n",
    "    target_names = np.unique(y_gen)\n",
    "    y_test_bin = label_binarize(y_gen, classes=np.arange(len(target_names)))\n",
    "    \n",
    "\n",
    "    roc_auc = roc_auc_score(y_test_bin, y_proba, multi_class='ovr')\n",
    "    \n",
    "    print(f'ROC-AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbd81ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[3263    0    0]\n",
      " [   0  156    0]\n",
      " [   0    0 3072]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3263\n",
      "           1       1.00      1.00      1.00       156\n",
      "           2       1.00      1.00      1.00      3072\n",
      "\n",
      "    accuracy                           1.00      6491\n",
      "   macro avg       1.00      1.00      1.00      6491\n",
      "weighted avg       1.00      1.00      1.00      6491\n",
      "\n",
      "ROC-AUC Score: 1.0\n",
      "Accuracy: 0.6666666666666666\n",
      "Confusion Matrix:\n",
      "[[312   0   0]\n",
      " [  0 312   0]\n",
      " [  0 312   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       312\n",
      "           1       0.50      1.00      0.67       312\n",
      "           2       0.00      0.00      0.00       312\n",
      "\n",
      "    accuracy                           0.67       936\n",
      "   macro avg       0.50      0.67      0.56       936\n",
      "weighted avg       0.50      0.67      0.56       936\n",
      "\n",
      "ROC-AUC Score: 0.9166392724085032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/Documents/studia/big_data/spark/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/michal/Documents/studia/big_data/spark/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/michal/Documents/studia/big_data/spark/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train a classifier (example with Gaussian Naive Bayes)\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(x_train, y_train)\n",
    "\n",
    "evaluate_model(nb_clf, x_test, y_test)\n",
    "evaluate_model(nb_clf, x_gen, y_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81de9c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[3263    0    0]\n",
      " [   0  156    0]\n",
      " [   0    0 3072]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3263\n",
      "           1       1.00      1.00      1.00       156\n",
      "           2       1.00      1.00      1.00      3072\n",
      "\n",
      "    accuracy                           1.00      6491\n",
      "   macro avg       1.00      1.00      1.00      6491\n",
      "weighted avg       1.00      1.00      1.00      6491\n",
      "\n",
      "ROC-AUC Score: 1.0\n",
      "Accuracy: 0.3333333333333333\n",
      "Confusion Matrix:\n",
      "[[  0   0 312]\n",
      " [312   0   0]\n",
      " [  0   0 312]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       312\n",
      "           1       0.00      0.00      0.00       312\n",
      "           2       0.50      1.00      0.67       312\n",
      "\n",
      "    accuracy                           0.33       936\n",
      "   macro avg       0.17      0.33      0.22       936\n",
      "weighted avg       0.17      0.33      0.22       936\n",
      "\n",
      "ROC-AUC Score: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/Documents/studia/big_data/spark/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/michal/Documents/studia/big_data/spark/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/michal/Documents/studia/big_data/spark/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(x_train, y_train)\n",
    "\n",
    "evaluate_model(rf_clf, x_test, y_test)\n",
    "evaluate_model(rf_clf, x_gen, y_gen)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
