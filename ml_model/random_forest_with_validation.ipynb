{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random forest z dopracownym skryptem do generowania danych pod walidację",
   "id": "7af7ec46af97e84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install scikit-learn\n",
    "!pip install imblearn\n",
    "!pip install scikit-learn\n",
    "!pip install xgboost"
   ],
   "id": "ae134c1efebfdbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "# Wczytanie danych z plików CSV\n",
    "ddos_df = pd.read_csv('/content/ddos-tcp-syn-flood.csv')\n",
    "normal_df = pd.read_csv('/content/normal-traffic.csv')\n",
    "port_scan_df = pd.read_csv('/content/port-scanning.csv')\n",
    "\n",
    "# Połączenie danych w jedną ramkę danych\n",
    "data = pd.concat([ddos_df, normal_df, port_scan_df], ignore_index=True)\n",
    "\n",
    "# Konwersja frame-time na milisekundy\n",
    "data['frame-time'] = pd.to_datetime(data['frame-time']).astype(int) / 10**6\n",
    "\n",
    "# Przetwarzanie danych\n",
    "def preprocess_data(df):\n",
    "    # Label encoding dla kolumny Attack_type\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Attack_type'] = label_encoder.fit_transform(df['Attack_type'])\n",
    "    \n",
    "    # Wybór cech (X) i etykiety (y)\n",
    "    X = df.drop(['Attack_type'], axis=1)\n",
    "    y = df['Attack_type']\n",
    "    \n",
    "    # Normalizacja danych\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    return X, y, scaler, label_encoder\n",
    "\n",
    "X, y, scaler, label_encoder = preprocess_data(data)\n",
    "\n",
    "# Zbalansowanie danych przy użyciu SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Budowa modelu Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Trenowanie modelu\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Ewaluacja modelu na zbiorze testowym\n",
    "y_pred_test = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "test_report = classification_report(y_test, y_pred_test, target_names=label_encoder.classes_)\n",
    "test_conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "print('Test Classification Report:')\n",
    "print(test_report)\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_conf_matrix)\n",
    "\n",
    "# Zapisanie modelu i przetworników\n",
    "with open('/content/network_attack_detector_rf.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "with open('/content/scaler_rf.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('/content/label_encoder_rf.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print(\"Model został wytrenowany i zapisany.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generowanie danych do walidacji",
   "id": "f7a1fe8281e846b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "def random_date(start, end):\n",
    "    return start + timedelta(seconds=random.randint(0, int((end - start).total_seconds())))\n",
    "\n",
    "start_date = datetime(2024, 5, 13, 16, 0, 0)\n",
    "end_date = datetime(2024, 5, 13, 19, 2, 37)\n",
    "\n",
    "def generate_sample(traffic_type):\n",
    "    frame_time = random_date(start_date, end_date).strftime('%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "    if traffic_type == \"Normal\":\n",
    "        ip_src_host = random.randint(0, 10)\n",
    "        ip_dst_host = random.randint(0, 10)\n",
    "        tcp_connection_syn = random.choice([0.0, 1.0])\n",
    "        tcp_connection_synack = random.choice([0.0, 1.0])\n",
    "        tcp_dstport = random.uniform(0, 7000)\n",
    "        tcp_len = random.uniform(0, 1500)\n",
    "        tcp_seq = random.uniform(0, 500000)\n",
    "    elif traffic_type == \"DDoS_TCP\":\n",
    "        ip_src_host = random.randint(0, 300000)\n",
    "        ip_dst_host = random.randint(0, 300000)\n",
    "        tcp_connection_syn = random.choice([0.0, 1.0])\n",
    "        tcp_connection_synack = random.choice([0.0, 1.0])\n",
    "        tcp_dstport = random.uniform(1000, 70000)\n",
    "        tcp_len = random.choice([0.0, 120.0])\n",
    "        tcp_seq = random.choice([0.0, 1.0])\n",
    "    elif traffic_type == \"Port_Scanning\":\n",
    "        ip_src_host = random.randint(0, 10)\n",
    "        ip_dst_host = random.randint(0, 10)\n",
    "        tcp_connection_syn = random.choice([0.0, 1.0])\n",
    "        tcp_connection_synack = random.choice([0.0, 1.0])\n",
    "        tcp_dstport = random.uniform(0, 10000)\n",
    "        tcp_len = random.uniform(0, 0)\n",
    "        tcp_seq = random.choice([0.0, 1.0])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid traffic type\")\n",
    "    \n",
    "    return [frame_time, ip_src_host, ip_dst_host, tcp_connection_syn, tcp_connection_synack, tcp_dstport, tcp_len, tcp_seq, traffic_type]\n",
    "\n",
    "def generate_random_data(num_samples):\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        traffic_type = random.choice([\"Normal\", \"DDoS_TCP\", \"Port_Scanning\"])\n",
    "        data.append(generate_sample(traffic_type))\n",
    "    \n",
    "    columns = ['frame-time', 'ip-src_host', 'ip-dst_host', 'tcp-connection-syn', 'tcp-connection-synack', 'tcp-dstport', 'tcp-len', 'tcp-seq', 'Attack_type']\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "validation_data = generate_random_data(10000)\n",
    "validation_data.to_csv('/content/validation-data.csv', index=False)"
   ],
   "id": "e3d3686eb11d4efb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Walidacja modelu",
   "id": "2a7e149d00f1d53a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "# Wczytanie nowego zbioru danych walidacyjnych\n",
    "validation_df = pd.read_csv('/content/validation-data.csv')\n",
    "\n",
    "# Wczytanie zapisanych modelu, skalera i kodera etykiet\n",
    "with open('/content/network_attack_detector_rf.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "with open('/content/scaler_rf.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "with open('/content/label_encoder_rf.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# Przetwarzanie nowego zbioru danych walidacyjnych\n",
    "validation_df['frame-time'] = pd.to_datetime(validation_df['frame-time']).astype(int) / 10**6\n",
    "X_validation = validation_df.drop(['Attack_type'], axis=1)\n",
    "y_true = label_encoder.transform(validation_df['Attack_type'])\n",
    "\n",
    "# Normalizacja danych walidacyjnych\n",
    "X_validation = scaler.transform(X_validation)\n",
    "\n",
    "# Przewidywanie etykiet na danych walidacyjnych\n",
    "y_pred_validation = model.predict(X_validation)\n",
    "\n",
    "# Mapowanie przewidywanych etykiet na oryginalne etykiety\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_validation)\n",
    "\n",
    "# Dodanie przewidywanych etykiet do danych walidacyjnych\n",
    "validation_df['Predicted_Attack_type'] = y_pred_labels\n",
    "\n",
    "# Wyświetlenie przykładowych wyników\n",
    "print(validation_df.head())\n",
    "\n",
    "# Ocena wyników\n",
    "accuracy = accuracy_score(y_true, y_pred_validation)\n",
    "report = classification_report(y_true, y_pred_validation, target_names=label_encoder.classes_)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_validation)\n",
    "\n",
    "# Wyświetlenie wyników oceny\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Zapisywanie wyników oceny do pliku tekstowego\n",
    "with open('/content/validation_evaluation.txt', 'w') as f:\n",
    "    f.write(f'Accuracy: {accuracy:.4f}\\n')\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(report)\n",
    "    f.write('Confusion Matrix:\\n')\n",
    "    f.write(np.array2string(conf_matrix))\n",
    "\n",
    "print(\"Ocena wyników walidacji została zapisana do pliku validation_evaluation.txt\")"
   ],
   "id": "1ce3da3663fba792"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
